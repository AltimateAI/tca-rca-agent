"""
RCA Agent - Root Cause Analysis with Claude
Follows fix-sentry-bug.md workflow with DRY_RUN support
"""

import asyncio
import json
import time
from typing import AsyncGenerator, Optional
from datetime import datetime

from .config import DRY_RUN, ANTHROPIC_API_KEY, MODEL_NAME, MCP_SERVERS

# Only import Claude SDK if not in dry-run mode
if not DRY_RUN:
    try:
        from anthropic import Anthropic
    except ImportError:
        print("‚ö†Ô∏è  Warning: anthropic package not installed")
        print("   Install with: pip install anthropic")
        DRY_RUN = True


class RCAAgent:
    """
    Root Cause Analysis Agent.

    Follows fix-sentry-bug.md workflow:
    - Phase 1-4: Analysis and present findings
    - Phase 5-7: Implementation after user approval
    - Phase 8: Hand off (NEVER creates PR automatically)
    """

    def __init__(self, memory_system=None):
        """
        Initialize RCA agent.

        Args:
            memory_system: Optional MemorySystem instance for learning
        """
        self.memory_system = memory_system
        if not DRY_RUN:
            self.client = Anthropic(api_key=ANTHROPIC_API_KEY)

    async def analyze_issue(
        self,
        issue_id: str,
        sentry_org: str = None,
    ) -> AsyncGenerator[dict, None]:
        """
        Analyze Sentry issue (Phases 1-4 of fix-sentry-bug.md).

        Yields progress events and final result.

        Args:
            issue_id: Sentry issue ID
            sentry_org: Sentry organization slug

        Yields:
            dict: Progress events with types: 'progress', 'result', 'error'
        """
        start_time = time.time()

        try:
            if DRY_RUN:
                async for event in self._dry_run_analysis(issue_id):
                    yield event
                return

            # Real Claude integration
            async for event in self._real_analysis(issue_id, sentry_org):
                yield event

        except Exception as e:
            yield {
                "type": "error",
                "data": {
                    "message": str(e),
                    "issue_id": issue_id,
                },
            }

    async def _dry_run_analysis(self, issue_id: str) -> AsyncGenerator[dict, None]:
        """
        Mock analysis for testing without API calls.

        Simulates the complete fix-sentry-bug.md workflow.
        """
        print(f"üîç [DRY RUN] Analyzing issue {issue_id}")

        # Phase 1: Initial Analysis
        phases = [
            {
                "phase": "Phase 1.1",
                "message": "Gathering bug information from Sentry",
                "duration": 0.5,
            },
            {
                "phase": "Phase 1.2",
                "message": "Checking project guidelines (CLAUDE.md, fix-sentry-bug.md)",
                "duration": 0.3,
            },
            {
                "phase": "Phase 1.3",
                "message": "Forming initial hypothesis about root cause",
                "duration": 0.4,
            },
            # Phase 2: Research
            {
                "phase": "Phase 2.1",
                "message": "Analyzing codebase patterns",
                "duration": 0.6,
            },
            {
                "phase": "Phase 2.2",
                "message": "Searching for industry best practices",
                "duration": 0.4,
            },
            {
                "phase": "Phase 2.3",
                "message": "Determining fix approach",
                "duration": 0.3,
            },
            # Phase 3: Impact Analysis
            {
                "phase": "Phase 3.1",
                "message": "Finding similar issues in same file",
                "duration": 0.5,
            },
            {
                "phase": "Phase 3.2",
                "message": "Searching for same pattern across codebase",
                "duration": 0.7,
            },
            {
                "phase": "Phase 3.3",
                "message": "Reviewing frontend impact",
                "duration": 0.4,
            },
            # Phase 4: Results
            {
                "phase": "Phase 4",
                "message": "Preparing findings for review",
                "duration": 0.3,
            },
        ]

        # Yield progress events
        for i, step in enumerate(phases, 1):
            yield {
                "type": "progress",
                "data": {
                    "phase": step["phase"],
                    "message": step["message"],
                    "step": i,
                    "total": len(phases),
                    "timestamp": datetime.utcnow().isoformat(),
                },
            }
            await asyncio.sleep(step["duration"])

        # Load learned patterns if memory system available
        learned_context = ""
        if self.memory_system:
            try:
                patterns = self.memory_system.get_all_patterns()
                if patterns:
                    learned_context = f"\n\nLearned patterns:\n{patterns[:500]}..."
            except Exception:
                pass  # Memory system not available in dry-run

        # Mock result following fix-sentry-bug.md structure
        mock_result = {
            "issue_id": issue_id,
            "sentry_url": f"https://sentry.io/issues/{issue_id}/",
            # Phase 1: Root Cause
            "root_cause": (
                "TypeError occurs because result.timestamp can be None when no data "
                "exists in the specified date range. The code attempts to call "
                ".replace(tzinfo=timezone.utc) on None, causing AttributeError.\n\n"
                "This is a common pattern where date filtering in one query doesn't "
                "match the filtering in another query, resulting in empty results."
            ),
            # Phase 2: Proposed Fix
            "fix_explanation": (
                "Add null check before accessing timestamp. Return 404 with helpful "
                "message if no data found. This follows the established pattern in "
                "app/schemas/pydantic_utils.py for handling missing data."
            ),
            "fix_approach": "Add defensive null check with explicit error handling",
            # Phase 3: Impact Scope
            "file_path": "app/service/queries.py",
            "function_name": "get_latest_run_timestamp",
            "same_file_issues": [
                {"line": 150, "pattern": ".replace() on timestamp", "needs_fix": True},
                {"line": 320, "pattern": ".replace() on created_at", "needs_fix": False},
                {"line": 450, "pattern": ".replace() on date", "needs_fix": True},
            ],
            "codebase_issues": [
                "app/service/metrics.py:89 - same pattern",
                "app/api/queries_v2.py:234 - same pattern",
            ],
            "related_sentry_issues": [],
            # Generated Fix Code
            "fix_code": '''def get_latest_run_timestamp(date_range: tuple[datetime, datetime]) -> datetime:
    """
    Get latest run timestamp with null safety.

    Args:
        date_range: Tuple of (start_date, end_date)

    Returns:
        Timestamp of latest run

    Raises:
        HTTPException: 404 if no run found in date range
    """
    start_date, end_date = date_range
    result = repository.get_latest_run(start_date, end_date)

    # PHASE 3.1 FIX: Add null check before accessing timestamp
    if not result or result.timestamp is None:
        raise HTTPException(
            status_code=404,
            detail=f"No run found in date range {start_date} to {end_date}"
        )

    # Safe to access timestamp now
    return result.timestamp.replace(tzinfo=timezone.utc)''',
            # Generated Test Code (Phase 5.1 - Comprehensive)
            "test_code": '''def test_get_latest_run_timestamp_no_data_returns_404():
    """
    Test Phase 3.1: Test that missing data returns 404 not AttributeError.

    Scenario: No data exists within the date range
    Expected: HTTPException with 404, not AttributeError on None.replace()
    """
    mock_repo = MagicMock()
    mock_repo.get_latest_run.return_value = None

    with pytest.raises(HTTPException) as exc:
        get_latest_run_timestamp((datetime(2024, 1, 1), datetime(2024, 1, 31)))

    assert exc.value.status_code == 404
    assert "No run found" in exc.value.detail


def test_get_latest_run_timestamp_null_timestamp_returns_404():
    """
    Test Phase 3.1: Test that None timestamp is handled gracefully.

    Scenario: Result exists but timestamp field is None
    Expected: HTTPException with 404
    """
    mock_repo = MagicMock()
    mock_result = MagicMock()
    mock_result.timestamp = None
    mock_repo.get_latest_run.return_value = mock_result

    with pytest.raises(HTTPException) as exc:
        get_latest_run_timestamp((datetime(2024, 1, 1), datetime(2024, 1, 31)))

    assert exc.value.status_code == 404


def test_get_latest_run_timestamp_valid_data_returns_utc():
    """
    Test Phase 3.1: Test that valid timestamp is properly converted to UTC.

    Scenario: Valid result with timestamp
    Expected: Timestamp converted to UTC timezone
    """
    mock_repo = MagicMock()
    mock_result = MagicMock()
    mock_result.timestamp = datetime(2024, 1, 15, 10, 30, 0)
    mock_repo.get_latest_run.return_value = mock_result

    result = get_latest_run_timestamp((datetime(2024, 1, 1), datetime(2024, 1, 31)))

    assert result.tzinfo == timezone.utc
    assert result.year == 2024
    assert result.month == 1
    assert result.day == 15''',
            # Quality metrics
            "confidence": 0.85,
            "analysis_time_seconds": 4.5,
            # Workflow compliance
            "frontend_impact": "NO",  # Breaking change?
            "requires_approval": True,  # Must get user approval before implementing
            "dry_run": True,
            "learned_context": learned_context,
        }

        # Phase 4: Present Findings
        yield {
            "type": "result",
            "data": mock_result,
        }

        print("‚úÖ [DRY RUN] Analysis complete - awaiting user approval")

    async def _real_analysis(self, issue_id: str, sentry_org: str) -> AsyncGenerator[dict, None]:
        """
        Real analysis using Sentry API and Claude.

        This replaces the mock implementation with actual API calls.
        """
        import requests
        import json
        from .config import SENTRY_AUTH_TOKEN, SENTRY_ORG, ANTHROPIC_API_KEY, MODEL_NAME

        start_time = time.time()

        # Use provided sentry_org or fall back to config
        org = sentry_org or SENTRY_ORG

        yield {
            "type": "progress",
            "data": {
                "phase": "Phase 1.1",
                "message": f"Fetching Sentry issue {issue_id} from {org}",
                "step": 1,
                "total": 8,
                "timestamp": datetime.utcnow().isoformat(),
            },
        }
        await asyncio.sleep(0.5)

        # Phase 1: Fetch Sentry Issue
        try:
            sentry_url = f"https://sentry.io/api/0/issues/{issue_id}/"
            headers = {"Authorization": f"Bearer {SENTRY_AUTH_TOKEN}"}

            response = requests.get(sentry_url, headers=headers, timeout=10)
            response.raise_for_status()
            issue_data = response.json()

            # Get latest event for stack trace
            events_url = f"https://sentry.io/api/0/issues/{issue_id}/events/latest/"
            event_response = requests.get(events_url, headers=headers, timeout=10)
            event_response.raise_for_status()
            event_data = event_response.json()

            # Extract relevant information
            error_type = issue_data.get("metadata", {}).get("type", "Unknown")
            error_value = issue_data.get("metadata", {}).get("value", "Unknown")
            culprit = issue_data.get("culprit", "")

            # Get stack trace
            stack_trace = ""
            entries = event_data.get("entries", [])
            for entry in entries:
                if entry.get("type") == "exception":
                    values = entry.get("data", {}).get("values", [])
                    if values:
                        stacktrace_data = values[0].get("stacktrace", {})
                        frames = stacktrace_data.get("frames", [])
                        if frames:
                            # Format stack trace
                            for frame in frames[-5:]:  # Last 5 frames
                                filename = frame.get("filename", "unknown")
                                function = frame.get("function", "unknown")
                                lineno = frame.get("lineNo", "?")
                                context = frame.get("context", [])
                                stack_trace += f"\n  File \"{filename}\", line {lineno}, in {function}\n"
                                if context:
                                    for ctx_line in context:
                                        stack_trace += f"    {ctx_line[1]}\n"

            if not stack_trace:
                stack_trace = json.dumps(event_data.get("entries", []), indent=2)[:500]

        except Exception as e:
            yield {
                "type": "error",
                "data": {
                    "message": f"Failed to fetch Sentry issue: {str(e)}",
                    "issue_id": issue_id,
                },
            }
            return

        yield {
            "type": "progress",
            "data": {
                "phase": "Phase 1.2",
                "message": f"Analyzing {error_type}: {error_value[:100]}",
                "step": 2,
                "total": 8,
                "timestamp": datetime.utcnow().isoformat(),
            },
        }
        await asyncio.sleep(0.5)

        # Phase 2: Load learned patterns
        learned_context = ""
        if self.memory_system:
            try:
                patterns = self.memory_system.get_all_patterns()
                if patterns and "active" in patterns.lower() or len(patterns) > 50:
                    learned_context = patterns[:1000]  # Limit for prompt caching
            except Exception:
                pass

        yield {
            "type": "progress",
            "data": {
                "phase": "Phase 2",
                "message": "Analyzing with Claude (this may take 30-60 seconds)",
                "step": 3,
                "total": 8,
                "timestamp": datetime.utcnow().isoformat(),
            },
        }

        # Phase 3: Analyze with Claude
        try:
            # Build comprehensive prompt
            learned_section = f"# Learned Patterns (from previous fixes)\n{learned_context}\n\n" if learned_context else ""

            prompt = f"""You are an expert software engineer analyzing a production error from Sentry.

# Sentry Issue Details
- Issue ID: {issue_id}
- Error Type: {error_type}
- Error Message: {error_value}
- Location: {culprit}
- Occurrences: {issue_data.get("count", "Unknown")}

# Stack Trace
{stack_trace}

{learned_section}# Your Task
Following the fix-sentry-bug.md workflow, provide:

1. **Root Cause**: Detailed explanation of WHY this error occurs (not just what)
2. **Fix Approach**: The strategy to fix this (e.g., "Add null check", "Fix date filter logic")
3. **File Path**: The file that needs to be changed (extract from stack trace)
4. **Function Name**: The specific function to fix
5. **Fix Code**: Complete function code with the fix applied (FULL function, not partial)
6. **Test Code**: Comprehensive pytest test case that would catch this bug

Return your response as JSON with this EXACT structure:
""" + """{
  "root_cause": "Detailed explanation...",
  "fix_approach": "Brief strategy...",
  "file_path": "path/to/file.py",
  "function_name": "function_name",
  "fix_code": "Complete fixed function code...",
  "test_code": "Complete pytest test...",
  "confidence": 0.85
}

IMPORTANT: Return ONLY valid JSON, no markdown formatting."""

            response = self.client.messages.create(
                model=MODEL_NAME,
                max_tokens=4096,
                messages=[{"role": "user", "content": prompt}]
            )

            result_text = response.content[0].text

            # Parse JSON response
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0].strip()

            analysis = json.loads(result_text)

        except Exception as e:
            yield {
                "type": "error",
                "data": {
                    "message": f"Claude analysis failed: {str(e)}",
                    "issue_id": issue_id,
                },
            }
            return

        yield {
            "type": "progress",
            "data": {
                "phase": "Phase 4",
                "message": "Analysis complete, preparing results",
                "step": 8,
                "total": 8,
                "timestamp": datetime.utcnow().isoformat(),
            },
        }

        # Build result
        result = {
            "issue_id": issue_id,
            "sentry_url": f"https://sentry.io/issues/{issue_id}/",
            "root_cause": analysis.get("root_cause", "Unknown"),
            "fix_explanation": f"{analysis.get('fix_approach', 'Unknown')} - {analysis.get('root_cause', '')[:200]}",
            "fix_approach": analysis.get("fix_approach", "Unknown"),
            "file_path": analysis.get("file_path", "unknown.py"),
            "function_name": analysis.get("function_name", "unknown"),
            "same_file_issues": [],  # Would need codebase search
            "codebase_issues": [],   # Would need codebase search
            "related_sentry_issues": [],
            "fix_code": analysis.get("fix_code", ""),
            "test_code": analysis.get("test_code", ""),
            "confidence": analysis.get("confidence", 0.5),
            "analysis_time_seconds": time.time() - start_time,
            "frontend_impact": "NO",  # Would need analysis
            "requires_approval": True,
            "dry_run": False,
            "learned_context": learned_context[:200] if learned_context else "",
        }

        yield {
            "type": "result",
            "data": result,
        }

        # Store pattern in memory
        if self.memory_system:
            try:
                self.memory_system.store_pattern(
                    error_type=error_type,
                    fix_approach=analysis.get("fix_approach", "Unknown"),
                    confidence=analysis.get("confidence", 0.5),
                    additional_metadata={"issue_id": issue_id}
                )
            except Exception:
                pass  # Don't fail if memory storage fails

        print(f"‚úÖ Real analysis complete for {issue_id}")

    async def implement_fix(
        self,
        analysis_result: dict,
        user_approved: bool,
    ) -> AsyncGenerator[dict, None]:
        """
        Implement fix after user approval (Phases 5-7 of fix-sentry-bug.md).

        This creates branch and commits but NEVER creates PR automatically.

        Args:
            analysis_result: Result from analyze_issue()
            user_approved: Whether user approved the fix

        Yields:
            dict: Progress events and handoff information
        """
        if not user_approved:
            yield {
                "type": "rejected",
                "data": {"message": "User rejected the proposed fix"},
            }
            return

        # Phases 5-7: Implementation
        import requests
        import base64
        from .config import GITHUB_TOKEN, GITHUB_OWNER, GITHUB_REPO
        from .code_merger import CodeMerger

        issue_id = analysis_result["issue_id"]
        file_path = analysis_result["file_path"]
        fix_code = analysis_result["fix_code"]
        function_name = analysis_result["function_name"]
        branch_name = f"fix/sentry-{issue_id}"

        # Phase 5: Get file from GitHub
        yield {
            "type": "progress",
            "data": {"message": f"Phase 5: Fetching {file_path} from GitHub..."},
        }

        try:
            headers = {
                "Authorization": f"Bearer {GITHUB_TOKEN}",
                "Accept": "application/vnd.github.v3+json",
            }

            # Get default branch
            repo_url = f"https://api.github.com/repos/{GITHUB_OWNER}/{GITHUB_REPO}"
            repo_response = requests.get(repo_url, headers=headers, timeout=10)
            repo_response.raise_for_status()
            default_branch = repo_response.json()["default_branch"]

            # Get file content
            file_url = f"https://api.github.com/repos/{GITHUB_OWNER}/{GITHUB_REPO}/contents/{file_path}"
            file_response = requests.get(file_url, headers=headers, timeout=10)
            file_response.raise_for_status()
            file_data = file_response.json()

            original_content = base64.b64decode(file_data["content"]).decode("utf-8")
            file_sha = file_data["sha"]

        except Exception as e:
            yield {
                "type": "error",
                "data": {"message": f"Failed to fetch file from GitHub: {str(e)}"},
            }
            return

        # Phase 6: Merge fix using AST
        yield {
            "type": "progress",
            "data": {"message": f"Phase 6: Applying fix to {function_name}..."},
        }

        try:
            updated_content = CodeMerger.merge_generic(
                original_content=original_content,
                fix_code=fix_code,
                file_path=file_path,
                function_name=function_name,
            )
        except Exception as e:
            yield {
                "type": "error",
                "data": {"message": f"Failed to merge fix: {str(e)}"},
            }
            return

        # Phase 7: Create branch and commit
        yield {
            "type": "progress",
            "data": {"message": f"Phase 7: Creating branch {branch_name}..."},
        }

        try:
            # Get default branch SHA
            ref_url = f"https://api.github.com/repos/{GITHUB_OWNER}/{GITHUB_REPO}/git/refs/heads/{default_branch}"
            ref_response = requests.get(ref_url, headers=headers, timeout=10)
            ref_response.raise_for_status()
            base_sha = ref_response.json()["object"]["sha"]

            # Create new branch (ignore if exists)
            create_ref_url = f"https://api.github.com/repos/{GITHUB_OWNER}/{GITHUB_REPO}/git/refs"
            create_ref_data = {
                "ref": f"refs/heads/{branch_name}",
                "sha": base_sha,
            }
            try:
                requests.post(create_ref_url, headers=headers, json=create_ref_data, timeout=10).raise_for_status()
            except:
                pass  # Branch might already exist

            # Update file content
            update_file_url = f"https://api.github.com/repos/{GITHUB_OWNER}/{GITHUB_REPO}/contents/{file_path}"
            commit_message = f"fix: {analysis_result['fix_explanation'][:50]}\n\nFixes Sentry issue {issue_id}\n\nCo-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"

            update_file_data = {
                "message": commit_message,
                "content": base64.b64encode(updated_content.encode()).decode(),
                "sha": file_sha,
                "branch": branch_name,
            }

            update_response = requests.put(update_file_url, headers=headers, json=update_file_data, timeout=10)
            update_response.raise_for_status()

        except Exception as e:
            yield {
                "type": "error",
                "data": {"message": f"Failed to create branch/commit: {str(e)}"},
            }
            return

        # Phase 8: Hand off (DO NOT create PR automatically)
        yield {
            "type": "handoff",
            "data": {
                "branch_name": branch_name,
                "file_path": file_path,
                "commit_message": commit_message,
                "github_url": f"https://github.com/{GITHUB_OWNER}/{GITHUB_REPO}/tree/{branch_name}",
                "testing_instructions": f"""
# Testing Instructions

1. Checkout the branch:
   git fetch origin {branch_name}
   git checkout {branch_name}

2. Review the fix in {file_path}

3. Run tests:
   pytest tests/ -v

4. Manually test the fix with:
   # Add specific test steps here

5. If validated, create PR manually on GitHub
""",
                "message": "‚úÖ Branch created and pushed. User must create PR manually.",
            },
        }


# Test the agent
if __name__ == "__main__":
    import asyncio

    async def test_agent():
        print("üß™ Testing RCA Agent in DRY_RUN mode\n")

        agent = RCAAgent()

        async for event in agent.analyze_issue("test-12345", "altimate-inc"):
            if event["type"] == "progress":
                data = event["data"]
                print(f"  [{data['step']}/{data['total']}] {data['phase']}: {data['message']}")
            elif event["type"] == "result":
                print("\n‚úÖ Analysis Result:")
                result = event["data"]
                print(f"   Issue ID: {result['issue_id']}")
                print(f"   Root Cause: {result['root_cause'][:100]}...")
                print(f"   Confidence: {result['confidence']:.0%}")
                print(f"   Fix Approach: {result['fix_approach']}")
            elif event["type"] == "error":
                print(f"\n‚ùå Error: {event['data']['message']}")

    asyncio.run(test_agent())
